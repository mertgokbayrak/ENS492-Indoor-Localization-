

# 📍 Indoor Localization Using Camera Images

## 🚀 Project Overview

Diving into the intricacies of autonomous navigation, our endeavor, "Indoor Localization Using Camera Images," aims to revolutionize how mobile robots perceive and navigate indoor spaces. By fusing the capabilities of camera images with the analytical power of deep learning, we set our sights on crafting a localization system that stands unrivaled in accuracy and efficiency.

### 👥 Team
- Ayça Elif Aktaş
- Mustafa Mert Gökbayrak


### 🎓 Supervisor
- Mustafa Ünel

### 📅 Start Date
- 12.11.2023

## 🌟 Motivation

The quest for impeccable indoor localization is more than a technical challenge; it's a gateway to elevating mobile robotics across logistics, healthcare, and beyond. Our vision is to pave the way for robots to navigate with unprecedented precision, ensuring their invaluable contributions are both effective and reliable.

## 🎯 Goals

- Forge a cutting-edge localization system employing CNNs, with a spotlight on YOLO, VGG, and AlexNet networks.
- Elevate robot awareness through pose estimation, transcending mere location coordinates to understand orientation and stance.
- Distill our findings into a robust prototype, rigorously tested to meet the stringent demands of dynamic indoor environments.

## 🔍 Technical Developments

We're setting the stage with the RGB-D Dataset from Microsoft's 7-Scenes, a treasure trove of depth-enhanced imagery pivotal for training our neural maestros. This dataset not only enriches our model's understanding of space but also introduces a layer of depth perception critical for accurate pose estimation.

## 🛠 Methodology

1. **Data Mastery**: Leveraging the RGB-D Dataset 7-Scenes, we embark on a journey to encapsulate a broad spectrum of indoor scenarios.
2. **Architectural Innovation**: Our experimental odyssey explores the realms of YOLO, VGG, and AlexNet, each a contender in the arena of image processing prowess.
3. **Pose Revelation**: Beyond mere localization, we delve into the realm of pose estimation, charting the robot's orientation with finesse.
4. **Prototype Realization**: The culmination of our efforts materializes as a tangible prototype, a testament to our dedication and a beacon for future exploration.

## 🧪 Experimental Design

Our methodology is a tapestry of precision and innovation, where each neural network undergoes rigorous evaluation for its role in room classification, coordinate determination, and the pioneering frontier of pose estimation. This holistic approach ensures our system is not just a navigator but a connoisseur of spatial intelligence.


## 📈 Future Work

The horizon beckons with promises of algorithmic refinement, expansive dataset exploration, and the integration of real-world feedback. Our blueprint is ever-evolving, guided by the twin stars of innovation and utility.
